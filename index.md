# Processing DP0.2 at FrDF: A comparison with DP0.2 catalogs produced at IDF

```{abstract}
The purpose of this note is to compare the final catalogs produced by the processing done in FrDF of the DP0.2 data with the reference catalogs produced at IDF.
```

## Introduction
In this note, we report the results of the comparison between DP0.2 catalogs produced at FrDF and the reference catalog produced at IDF.

In the context of the Data Preview 0.2 (DP0.2), the Data Release Production pipelines have been executed on the DC-2 simulated dataset (generated by the Dark Energy Science Collaboration, DESC).
This dataset includes 20 000 simulated exposures, representing 300 square degrees of Rubin images with a typical depth of 5 years.
DP0.2 ran at the Interim Data Facility, and the full exercise was independently replicated at FrDF (CC-IN2P3) and described in {cite:t}`LeBoulch.2024`.

In this note we will start describing the catalogs and how we retrieved the data.
Then we report the analysis performed on each table, checking two main objectives: how the sources' positions in the sky match, and how the sources' fluxes compare (when applicable).

The data and notebooks used are available in the [CC-IN2P3 GitLab](https://gitlab.in2p3.fr/gabriele.mainetti/dp02_analysis).

## The catalogs in Qserv

The catalogs have been ingested in Qserv production instance at FrDF:
1. dp02_dc2_catalogs_frdf catalog produced at CC-IN2P3 (hereafter FrDF catalog)
2. dp02_dc2_catalogs catalog produced at IDF (hereafter IDF catalog)

For the FrDF catalog, two tables are missing (TruthSummary and MatchesTruth) because that tables require post processing before to be ingested in Qserv.

In the following image you can see the number of line per table in FrDF and IDF catalogs. CcdVisit and Visit, produced by pipeline Step 7, have been produced twice at FrDF. For our scope, the FrDF data have been filtered to remove the rows in double. This problem needs to be adressed: **we have to be able to flag the non valid tables to detect them before the ingestion process**.

```{figure} ./images/table_qserv.png
Number of lines per table in DPO.2 FrDF and IDF catalogs. 
```

It is not possible compare the full catalogs, so for the analysis reported here we used a subsample of both the catalogs selected using a spatial query as this: 

```
SELECT <column1>, <column2>, ...,<columnN> from <table> where scisql_s2PtInCircle(<ra>, <decl>, 60.0, -30.0, 0.5) = 1 limit 5000000
```

We limited the number of retrieved lines to 5M but for tables with a large number of lines (sources) we reduced also the query radius: a radius of 0.5 degree is to large and the number of sources in the area defined by the circle exceed largley the limits we imposed on the number of the lines. For this reason the catalogs retrieved are not comparable because the sources in the tables are not covering the same region as shown in the following image for ForcedSource table retrieved in a radius of 0.5deg, where in red you see the objects extracted from FrDF and in blue the objects extracted from the IDF.

```{figure} ./images/forced_source.png
Example of source extraction not covering the same region. 
```

To reduce the table size we also retrieved a subsamble of columns (ra, dec and fluxes). Only for few small table we retrieved all columns.

The fluxes has been converted to magnitude AB using UDF SQL function `scisql_nanojanskyToAbMag` integrated in Qserv.

All the queries used for each table are reported in query notebook.

The analysis has been performed offline: all the tables have been retrieved once and stored locally as fits files (available in fits directory in this repository). For each table a file called `<df>_<table>.fits` has been generated and for each table a new column (DF) has been added allowing to identify easily the data origin during the analysis.

Topcat has been used to quick validate the retrieved datasets and to filter out the line in double for Visit and CcdVisit tables.


## References

```{bibliography}
```
